---
title: "data_cleaning"
format: html
editor: visual
---

## Instructions

-   RUN harmonisation before running this script

## Known issues

Issues with the dataset:

-   Lots of people are getting married right at the end of the risk window, I feel like that's something wrong with the conditions for the event.

<!-- -->

-   A new unique identifier is needed, since respid from Czechia round 2 overlaps with respids of Estonia and Italy round 2

    -   Solved for now by generating a new respid based on rownumber

-   Kazakhstan is disappearing despite officially being in harmonized_histories_I

    -   IT'S MISCODED - the iso3n code in the file 860 is for Uzbekistan, not Kazakhstan, it should be 398

## Initial setup

```{r packages}
#| message: false
#| warning: false

# General functionality
library(tidyverse)

# For importing the data
library(sjmisc)
library(haven)
library(janitor)
library(countrycode)
```

## Importing raw data

```{r raw-data}
#| message: false
#| warning: false

# for getting correct file paths
source("config.R")

# getting in all the harmonized histories (downloaded the latest version from September)
hh1 <- read_dta(paste0(data_path, "/harmonized_histories.dta")) |> clean_names("snake")
hh2 <- read_dta(paste0(data_path, "/harmonized_histories_I.dta")) |> clean_names("snake")
hh3 <- read_dta(paste0(data_path, "/harmonized_histories_II.dta")) |> clean_names("snake")

# appending them all onto each other with sjmisc to preserve labels
# the labels diverge with hhII, it throws up a lot of warnings, so that's why I silence them
rough_df <- add_rows(hh1, hh2, hh3, id = "source_dataset")
```

## Cleaning micro-data

```{r initial-clean}
micro_clean <- rough_df |> 
  
  # tidying up country variables
  mutate(
    country = as.character(country), # convert to character first
    # pad the ISO codes so they work (Austria and Belgium need a 0 at the beginning)
    country_code_iso = str_pad(country, width = 4, side = "left", pad = "0")
  ) |> 
  
  separate_wider_position(
    country_code_iso,
    widths = c(country_code = 3, round = 1)
  ) |> 
  
  # convert ISO code to country name
  mutate(
    country_code = as.numeric(country_code),
    country = countrycode(country_code, "iso3n", "country.name"),
    
    # Uzbekistan is actually Kazakhstan in this dataset, miscoded variable
    country = if_else(country == "Uzbekistan", "Kazakhstan", country)
  ) |> 
  
  select(
    # stratifying things
    source_dataset, # Which harmonized histories dataset is the obs from
    country, # country
    round, # survey round
    
    # basic respondent information
    respid,
    arid, # respondent IDs
    sex,
    
    year_s, # year of survey
    
    born_y, # year of birth
    
    native, # born in country of interview?
    
    # Education
    edu_cou, # country specific highest level of education
    isced_7, # isced coded highest level of education
    inschool,
    
    # Education dates
    edu_y,
    iedu_y, # Imputation with help of modal ages by levels of education if imputed year>year of interview==>.a
    
    # Weights:
    hhwgt,
    perswgt,
    kishwgt,
    
    # Union information (not marriage specific)
    uninum, # number of unions
    starts_with("union_"), # union order and all the associated dates
    
    starts_with("sep_"), # union dissolution and associated dates
    
    # Marriage specific information
    starts_with("marr_"), # type of marriage and dates
    
    starts_with("div_"), # divorce information
    
    # Left truncated things from the BHPS
    starts_with("lt")
  )

# unloading previous dataset
rm(rough_df)
```

## Adding in final harmonised dataset

```{r add-hh4}
micro_clean <- micro_clean |> 
  mutate(respid = as.character(respid)) |> 
  add_rows(hh4, id = "harmonised")

# unload intermediate massive dfs
rm(list = ls(pattern = "^hh"))
```

## Isled recode

```{r isled-recode}
# added in kazakhstan and croat recodes
isled_coding <- read_csv(paste0(data_path, "/isled_me.csv")) |> 
  
  # fixing values within the codebook
  mutate(
    isled_7 = case_when(
      `isled_7 (0+1+2)` > 100 ~ (isled_1 + isled_2)/2,
      is.na(`isled_7 (0+1+2)`) ~ NA,
      .default = `isled_7 (0+1+2)`
    ),
    isled_8 = case_when(
      `isled_8 (5+6)` > 100 ~ (isled_5 + isled_6)/2,
      is.na(`isled_8 (5+6)`) ~ NA,
      .default = `isled_8 (5+6)`
    ),
    isled_9 = case_when(
      `isled_9 (3+4)` > 100 ~ (isled_3 + isled_4)/2,
      is.na(`isled_9 (3+4)`) ~ NA,
      .default = `isled_9 (3+4)`
    )
  ) |> 
  
  # tidying the codebook - putting it into long format for left_join() later
  select(-`isled_7 (0+1+2)`, -`isled_8 (5+6)`, -`isled_9 (3+4)`) |> 
  pivot_longer(
    cols = starts_with("isled"),
    names_to = "isced_7",
    names_prefix = "isled_",
    values_to = "isled",
    values_drop_na = TRUE
  ) |>  
  mutate(
    isced_7 = as.numeric(isced_7)
  )

# recoding the isced_7 values
micro_clean <- 
  left_join(micro_clean, isled_coding, by = join_by(country, isced_7))

# relocate needed a new pipe
micro_clean <- micro_clean |> 
  relocate(isled, .after = isced_7)

rm(isled_coding)
```

## Create new respid

The prepackaged one contains duplicates between different countries

```{r respid-fix}
micro_clean <- micro_clean |> 
  mutate(respid = row_number())
```

## Expansion into long-format

This is computationally very demanding, the resulting df has over 4 million rows. Make sure you have a powerful computer or be prepared to sit for a loooooong time

## Identifying 1st marriage

New approach compared to my original document:

1.  Create person-marriage df.
2.  Cut out the extra marriages after the first.
3.  Join these by respid (need a new unique identfier)

```{r identify-first-marriage}
marriage_order <- micro_clean |> 
  select(respid, marr_1:marr_10) |> 
  pivot_longer(
    cols = marr_1:marr_10,
    names_to = "order",
    names_prefix = "marr_",
    values_to = "married"
  ) |> 
  left_join(
    micro_clean |> 
      select(respid, marr_y1:marr_y10) |> 
      pivot_longer(
        cols = marr_y1:marr_y10,
        names_to = "order",
        names_prefix = "marr_y",
        values_to = "year"
      ),
    by = c("respid", "order")
  ) |> 
  
  group_by(respid) |> 
  filter(
    # keep marriages
    married == 1 |
    # or keep first row if there are none
    (all(is.na(married) | married != 1) & row_number() == 1)
  ) |> 
  # If there are multiple marriages, keep only the first one
  slice(1) |> 
  ungroup() |> 
  
  mutate(
    married = if_else(is.na(married), 0, married)
  )

write.csv(marriage_order, file = paste0(data_path, "/intermediate_output/marriage_order.csv"))
```

## Pivot to long

ISSUE detected - everyone ever married keeps the married tag but also has duration 26,

```{r long-format}
analysis <- micro_clean |> 
  select(-starts_with("marr_"), -starts_with("union_"), -starts_with("sep_"), -starts_with("ltunion"), -starts_with("ltmarr_"), -starts_with("div_")) |> 
  
  left_join(
    marriage_order,
    by = join_by("respid")
  ) |> 
  
  mutate(
    duration = case_when(
      # married and did that within age 41
      year - born_y < 41 & married == 1 ~ year - born_y - 15 + 1,
      # I add the 1 because duration 0 means they got married in the same year they entered risk, but I still need that observation
      
      # didn't marry within age 41
      year_s - born_y < 41 & married == 0 ~ year_s - born_y - 15 + 1,
      
      # didn't marry and older than age 41 at date of interview
      year_s - born_y > 40 ~ 26, # FIX not sure if 26 or 27
      
      .default = NA
    ),
    
    age_marr = year - born_y,
    age_s = year_s - born_y
  ) |> 
  relocate(order:age_s, .after = born_y) |> 
  
  # get rid of those who married before 15
  filter(duration > 0) |> 
  uncount(weights = duration) |> 
  
  # time variable and current year
  group_by(respid) |> 
  mutate(
    time = row_number(),
    obs_year = born_y + time - 1 + 15
  ) |> 
  ungroup() |>
  
  relocate(time:year, .after = year_s) |> 
   
  
  # creating the dependent variable
  group_by(respid) |> 
  mutate(
    # ISSUE - added a condition that they also have to be younger than 41 at marriage
    event = if_else(
      max(time) == time & married == 1 & age_marr < 41,
      1,
      0
    )
  ) |> 
  relocate(event, .after = married) |> 
  ungroup()

rm(marriage_order)
```

## Cohabitation indicator

```{r construct-cohabitation-indicator}

# expand it so each observation is respondent-union
union_order <- micro_clean |>
  select(respid, union_1:union_10, year_s) |> 
  pivot_longer(
    cols = union_1:union_10,
    names_to = "order",
    names_prefix = "union_",
    values_to = "in_union"
  ) |> 
  
  # separate pivot for for the years and join them up
  left_join(
    micro_clean |> 
      select(respid, union_y1:union_y10) |> 
      pivot_longer(
        cols = union_y1:union_y10,
        names_to = "order",
        names_prefix = "union_y",
        values_to = "year_start"
      ),
    by = c("respid", "order")
  ) |> 
  
  # separations
  left_join(
    micro_clean |> 
      select(respid, sep_1:sep_10) |> 
      pivot_longer(
        cols = sep_1:sep_10,
        names_to = "order",
        names_prefix = "sep_",
        values_to = "separated"
      ),
    by = c("respid", "order")
  ) |>  
      
  left_join(
    micro_clean |> 
      select(respid, sep_y1:sep_y10) |> 
      pivot_longer(
        cols = sep_y1:sep_y10,
        names_to = "order",
        names_prefix = "sep_y",
        values_to = "year_end"
      ),
    by = c("respid", "order")
  ) |> 
  
  group_by(respid) |> 
  filter(cumsum(in_union == 0) < 2) |> # counts how many rows have a 0, once there's more than 1 they are filtered
  filter(in_union == 1 | 
         (in_union == 0 & lag(separated) == 1) | 
         all(in_union == 0)) |>  
  # keeps either observations with unions, or those that have a previous separation, or those where there are just 0 in respid
  ungroup()

write.csv(union_order, file = paste0(data_path, "/intermediate_output/union_order.csv"))

person_union_year <- union_order |> 
  filter(in_union == 1) |> 
  mutate(spell = case_when(
    separated == 0 ~ year_s - year_start + 1,
    separated > 0 ~ year_end - year_start + 1
  )) |> 
  filter(!is.na(spell)) |> 
  filter(!is.na(spell) & spell > 0)  |>  
  uncount(weights = spell) |>
  group_by(respid) |>  
  mutate(
    time = row_number(),
    obs_year = year_start + time - 1
  ) |>  
  ungroup()  |>  
  select(respid, in_union, obs_year)

analysis <- analysis |> 
  left_join(person_union_year, by = join_by(respid, obs_year))  |>
  relocate(in_union, .after = event) |> 
  mutate(
    in_union = if_else(is.na(in_union), 0, in_union)
  ) |> 
  group_by(respid) |> 
  
  # Condition that they had to be cohabiting at least a full year before marriage
  mutate(in_union = if_else(event == 1 & (is.na(lag(in_union)) | lag(in_union) == 0), 0, in_union)) |> 
  ungroup()
```

## Countries to get rid of

-   UK BHPS - patchy education measures, lots of missing information on union formation. There is now a GGS wave that's higher quality, it's worth getting rid of the headache. (UK round 1)

```{r finalise-for-analysis}
analysis <- analysis |> 
  # Getting rid of countries I've decided to leave out
  filter(!(country == "United Kingdom" & round == 1)) |> 
  
  # Imputing age at finishing school by taking the median school leaving age in each country-isled combo
  group_by(country, isled) |> 
  mutate(
    median_age_edu_y = median(iedu_y - born_y, na.rm = TRUE),
    iedu_y_mod = born_y + median_age_edu_y
  ) |> 
  relocate(median_age_edu_y, .after = iedu_y) |> 
  relocate(iedu_y_mod, .after = iedu_y) |>
  ungroup() |> 
  
   # modified enrolment indicator
  mutate(
    iedu_y = if_else(is.na(iedu_y), edu_y, iedu_y),
    enrol_mod = case_when(
      is.na(iedu_y) &  iedu_y_mod >= obs_year ~ 1,
      is.na(iedu_y) &  iedu_y_mod < obs_year ~ 0,
      iedu_y >= obs_year ~ 1,
      iedu_y < obs_year ~ 0,
      .default = NA
    )
  ) |> 
  relocate(enrol_mod, .after = age_s)
```

## Selection of respondents for analysis

-   added a "missing by design" 3rd category for foreign_born for Hungary and the Netherlands round 1.

```{r selection}
analysis_select <- analysis |>
  
  select(-arid, -kishwgt, -hhwgt) |> 
  
  filter(age_s < 66) |> 
  mutate(
    foreign_born = as.factor(case_when(
      native == 1 ~ "No",
      native == 2 ~ "Yes",
      country == "Hungary" & round == 1 ~ "Missing by design",
      country == "Netherlands" & round == 1 ~ "Missing by design",
      TRUE ~ NA
    )),
    male = case_when(
      sex == 1 ~ 1,
      sex == 2 ~ 0,
      TRUE ~ NA
    ),
    
    marriage_cohort = born_y + 15
  ) |> 
  select(-sex, -native, -lhi02, -lhi01, -dem21, -inschool, -harmonised, -source_dataset, -...1, -...2, -edu_cou, -isced_7)

# write.csv(analysis, file = paste0(data_path, "/intermediate_output/analysis.csv"))
```
